# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-community
  labels:
    app: {{ .Release.Name }}-community
spec:
  replicas: {{ .Values.community.replicas }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-community
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-community
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        rollme: {{ randAlphaNum 5 | quote }}
    spec:
      serviceAccountName: {{ .Release.Name }}-sa
      initContainers:
      {{- if not .Values.community.config.database.external }}
      - name: wait-for-postgres
        image: postgres:15-alpine
        command:
          - /bin/sh
          - -c
          - |
            until pg_isready -h {{ .Release.Name }}-postgresql -p 5432 -U {{ .Values.community.config.postgresql.username }}; do
              sleep 2
            done
      {{- end }}
      - name: wait-for-migration
        image: bitnami/kubectl:latest
        command:
          - /bin/sh
          - -c
          - |
            echo "Waiting for migration to complete..."
            while true; do
              echo "Running kubectl command to check job status..."
              if [ "$(kubectl get job {{ .Release.Name }}-db-migration -o jsonpath='{.status.succeeded}')" = "1" ]; then
                echo "Migration completed."
                break
              fi
              echo "Migration not yet completed. Retrying in 2 seconds..."
              sleep 2
            done
      containers:
        - name: community
          image: "{{ .Values.community.image.repository }}:{{ .Values.community.image.tag }}"
          imagePullPolicy: {{ .Values.community.image.pullPolicy }}
          ports:
          {{- if .Values.community.config.community.enableSubpathBasedAccess }}
            - containerPort: {{ .Values.service.ports.subpath.targetPort }}
              name: {{ .Values.service.ports.subpath.name }}
          {{- else }}
            - containerPort: {{ .Values.service.ports.backend.targetPort }}
              name: {{ .Values.service.ports.backend.name }}
            - containerPort: {{ .Values.service.ports.frontend.targetPort }}
              name: {{ .Values.service.ports.frontend.name }}
            - containerPort: {{ .Values.service.ports.admin.targetPort }}
              name: {{ .Values.service.ports.admin.name }}
          {{- end }}
          envFrom:
            - configMapRef:
                name: {{ .Release.Name }}-community-config
          {{- with .Values.community.envOverrides }}
          env:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          resources:
            {{- toYaml .Values.community.resources | nindent 12 }}
      {{- if .Values.community.affinity.enabled }}
      affinity:
        {{- if .Values.community.affinity.nodeAffinity}}
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "kubernetes.io/hostname"
                    operator: In
                    values:
                      {{- $nodeHostnames := .Values.community.affinity.nodeAffinity.nodeHostnames | split "," }}
                      {{- range $node := $nodeHostnames }}
                      - "{{ $node }}"
                      {{- end }}
        {{- end }}
        {{- with .Values.community.affinity.tolerations }}
        toleration: 
          {{ . | toYaml | nindent 8 }}
        {{- end }}
        {{- with .Values.community.affinity.nodeSelector }}
        nodeSelector: 
          {{ . | toYaml | nindent 8 }}
        {{- end }}
      {{- end }}